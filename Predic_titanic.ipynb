{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se importan la librerias a utilizar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Se importa los datos a utilizar de la web\n",
    "url_test = 'https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/test.csv'\n",
    "url_train = 'https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/train.csv'\n",
    "\n",
    "df_test = pd.read_csv(url_test)\n",
    "df_train = pd.read_csv(url_train)\n",
    "\n",
    "#Se guardan los datos en un archivo para siempre tenerlos disponibles\n",
    "dir_test = '/Users/ligdigonzalez/Documents/ML/Proyectos/Titanic/titanic_test.csv'\n",
    "dir_train = '/Users/ligdigonzalez/Documents/ML/Proyectos/Titanic/titanic_train.csv'\n",
    "\n",
    "df_test.to_csv(dir_test)\n",
    "df_train.to_csv(dir_train)\n",
    "\n",
    "#Importar los datos de los archivos .csv almacenados\n",
    "df_test = pd.read_csv(dir_test)\n",
    "df_train = pd.read_csv(dir_train)\n",
    "#Verifico la cantidad de datos que hay en los dataset\n",
    "print('Cantidad de datos:')\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "#Verifico el tipo de datos contenida en ambos dataset\n",
    "print('Tipos de datos:')\n",
    "print(df_train.info())\n",
    "print(df_test.info())\n",
    "\n",
    "#Verifico los datos faltantes de los dataset\n",
    "print('Datos faltantes:')\n",
    "print(pd.isnull(df_train).sum())\n",
    "print(pd.isnull(df_test).sum())\n",
    "\n",
    "#Verifico las estadísticas del dataset\n",
    "print('Estadísticas del dataset:')\n",
    "print(df_train.describe())\n",
    "print(df_test.describe())\n",
    "#Cambio los datos de sexos en números\n",
    "df_train['Sex'].replace(['female','male'],[0,1],inplace=True)\n",
    "df_test['Sex'].replace(['female','male'],[0,1],inplace=True)\n",
    "\n",
    "#Cambio los datos de embarque en números\n",
    "df_train['Embarked'].replace(['Q','S', 'C'],[0,1,2],inplace=True)\n",
    "df_test['Embarked'].replace(['Q','S', 'C'],[0,1,2],inplace=True)\n",
    "\n",
    "#Reemplazo los datos faltantes en la edad por la media de esta columna\n",
    "print(df_train[\"Age\"].mean())\n",
    "print(df_test[\"Age\"].mean())\n",
    "promedio = 30\n",
    "df_train['Age'] = df_train['Age'].replace(np.nan, promedio)\n",
    "df_test['Age'] = df_test['Age'].replace(np.nan, promedio)\n",
    "\n",
    "#Creo varios grupos de acuerdo a bandas de las edades\n",
    "#Bandas: 0-8, 9-15, 16-18, 19-25, 26-40, 41-60, 61-100\n",
    "bins = [0, 8, 15, 18, 25, 40, 60, 100]\n",
    "names = ['1', '2', '3', '4', '5', '6', '7']\n",
    "df_train['Age'] = pd.cut(df_train['Age'], bins, labels = names)\n",
    "df_test['Age'] = pd.cut(df_test['Age'], bins, labels = names)\n",
    "\n",
    "#Se elimina la columna de \"Cabin\" ya que tiene muchos datos perdidos\n",
    "df_train.drop(['Cabin'], axis = 1, inplace=True)\n",
    "df_test.drop(['Cabin'], axis = 1, inplace=True)\n",
    "\n",
    "#Elimino las columnas que considero que no son necesarias para el analisis\n",
    "df_train = df_train.drop(['PassengerId','Name','Ticket'], axis=1)\n",
    "df_test = df_test.drop(['Name','Ticket'], axis=1)\n",
    "\n",
    "#Se elimina las filas con los datos perdidos\n",
    "df_train.dropna(axis=0, how='any', inplace=True)\n",
    "df_test.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "#Verifico los datos\n",
    "print(pd.isnull(df_train).sum())\n",
    "print(pd.isnull(df_test).sum())\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "print(df_test.head())\n",
    "print(df_train.head())\n",
    "#Separo la columna con la información de los sobrevivientes\n",
    "X = np.array(df_train.drop(['Survived'], 1))\n",
    "y = np.array(df_train['Survived'])\n",
    "\n",
    "#Separo los datos de \"train\" en entrenamiento y prueba para probar los algoritmos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "##Regresión logística\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "print('Precisión Regresión Logística:')\n",
    "print(logreg.score(X_train, y_train))\n",
    "\n",
    "##Support Vector Machines\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "print('Precisión Soporte de Vectores:')\n",
    "print(svc.score(X_train, y_train))\n",
    "\n",
    "##K neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "print('Precisión Vecinos más Cercanos:')\n",
    "print(knn.score(X_train, y_train))\n",
    "ids = df_test['PassengerId']\n",
    "\n",
    "##Regresión logística\n",
    "prediccion_logreg = logreg.predict(df_test.drop('PassengerId', axis=1))\n",
    "out_logreg = pd.DataFrame({ 'PassengerId' : ids, 'Survived': prediccion_logreg })\n",
    "print('Predicción Regresión Logística:')\n",
    "print(out_logreg.head())\n",
    "\n",
    "##Support Vector Machines\n",
    "prediccion_svc = svc.predict(df_test.drop('PassengerId', axis=1))\n",
    "out_svc = pd.DataFrame({ 'PassengerId' : ids, 'Survived': prediccion_svc })\n",
    "print('Predicción Soporte de Vectores:')\n",
    "print(out_svc.head())\n",
    "\n",
    "##K neighbors\n",
    "prediccion_knn = knn.predict(df_test.drop('PassengerId', axis=1))\n",
    "out_knn = pd.DataFrame({ 'PassengerId' : ids, 'Survived': prediccion_knn })\n",
    "print('Predicción Vecinos más Cercanos:')\n",
    "print(out_knn.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
